{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el conjunto de datos de cáncer de mama utilizando load_breast_cancer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este conjunto de datos se divide en dos partes: entrenamiento (X_train y y_train) y prueba (X_test y y_test). La división se realiza con train_test_split() y se utiliza stratify=cancer.target para mantener la proporción de clases en ambos conjuntos, lo cual es importante para evitar sesgos en la evaluación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion del GridSearchCV y Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Pipeline se utiliza en GridSearchCV, realiza la búsqueda de hiperparámetros. En este caso, knn_param_grid define un rango de valores para n_neighbors (de 1 a 19). GridSearchCV realiza validación cruzada con 5 particiones (cv=5) y utiliza f1 como métrica de evaluación. \n",
    "\n",
    "Esto significa que el proceso probará todas las combinaciones de parámetros en knn_param_grid y seleccionará la que maximice el f1-score promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros K-NN:  {'knn__n_neighbors': 14}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': range(1, 20)\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "knn_best = grid.best_estimator_\n",
    "y_pred_knn = knn_best.predict(X_test)\n",
    "y_prob_knn = knn_best.predict_proba(X_test)[:, 1] \n",
    "print(\"Mejores parametros K-NN: \", grid.best_params_)\n",
    "\n",
    "\n",
    "Au_knn_precision = precision_score(y_test, y_pred_knn)\n",
    "Au_knn_recall = recall_score(y_test, y_pred_knn)\n",
    "Au_knn_f1 = f1_score(y_test, y_pred_knn)\n",
    "Au_knn_auc = roc_auc_score(y_test, y_prob_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se selecciona el mejor modelo (knn_best) basado en los parámetros que proporcionaron el mejor f1-score. Se usan estos parámetros para hacer predicciones en el conjunto de prueba (X_test). Se calculan las métricas de evaluación, precisión, recall, f1-score y AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regresion logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza GridSearchCV para ajustar el parámetro C con una serie de valores predefinidos ([0.001, 0.01, 0.1, 1, 10, 100]). Al igual que con KNN, GridSearchCV realiza validación cruzada con 5 particiones y utiliza f1 como métrica de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros Regresion Logistica {'logreg__C': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg = Pipeline([\n",
    "    ('logreg', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "\n",
    "logreg_param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "logreg_grid = GridSearchCV(logreg, logreg_param_grid, cv=5, scoring='f1')\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "\n",
    "logreg_best = logreg_grid.best_estimator_\n",
    "au_pred_logreg = logreg_best.predict(X_test)\n",
    "au_prob_logreg = logreg_best.predict_proba(X_test)[:, 1]  \n",
    "print(\"Mejores parametros Regresion Logistica\", logreg_grid.best_params_)\n",
    "\n",
    "Au_logreg_precision = precision_score(y_test, au_pred_logreg)\n",
    "Au_logreg_recall = recall_score(y_test, au_pred_logreg)\n",
    "Au_logreg_f1 = f1_score(y_test, au_pred_logreg)\n",
    "Au_logreg_auc = roc_auc_score(y_test, au_prob_logreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de completar la búsqueda, se selecciona el mejor modelo (logreg_best) en función de los parámetros que maximizaron el f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuadro de comparación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Modelo  Precision    Recall  f1-score       AUC\n",
      "0                 K-NN   0.914894  0.955556  0.934783  0.961006\n",
      "1  Logistic Regression   0.966292  0.955556  0.960894  0.977987\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Modelo': ['K-NN', 'Logistic Regression'],\n",
    "    'Precision': [Au_knn_precision, Au_logreg_precision],\n",
    "    'Recall': [Au_knn_recall, Au_logreg_recall],\n",
    "    'f1-score': [Au_knn_f1, Au_logreg_f1],\n",
    "    'AUC': [Au_knn_auc, Au_logreg_auc]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(results)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados comparativos entre el modelo KNN y la Regresión Logística muestran que, en general, la Regresión Logística supera al KNN en todas las métricas evaluadas. \n",
    "La Regresión Logística tiene una precisión (0.955) y un f1-score (0.950) ligeramente superiores en comparación con el KNN, que tiene valores de 0.933 en ambas métricas. Además, el AUC de la Regresión Logística (0.992) es significativamente mejor que el del KNN (0.954), indicando una mayor capacidad de discriminación del modelo de Regresión Logística. Estos resultados sugieren que, en este caso, la Regresión Logística es más efectiva para clasificar los datos de cáncer de mama en comparación con el modelo KNN, ofreciendo una mejor combinación de precisión y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ajustar manualmente los hiperparámetros del modelo K-Nearest Neighbors (KNN), se prueba una serie de valores para el parámetro n_neighbors, que representa el número de vecinos más cercanos que el clasificador considerará. El rango de valores probado es de 1 a 19. Para cada valor de n_neighbors, se entrena un modelo KNN y se evalúa su rendimiento utilizando validación cruzada con 5 particiones (cv=5). \n",
    "\n",
    "La métrica utilizada para evaluar el rendimiento es el f1-score, que es una medida que combina precisión y recall. Se calcula el promedio de f1-scores obtenidos en las 5 particiones y se selecciona el valor de n_neighbors que proporciona el mejor rendimiento promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K-NN parameters: 14\n",
      "K-NN Precision: 0.91489, Recall: 0.95556, F1-Score: 0.93478, AUC: 0.96101\n"
     ]
    }
   ],
   "source": [
    "mejor_knn_score = 0\n",
    "mejor_knn_param = None\n",
    "\n",
    "for n_neighbors in range(1, 20):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='f1')\n",
    "    avg = np.mean(scores)\n",
    "    \n",
    "    if avg > mejor_knn_score:\n",
    "        mejor_knn_score = avg\n",
    "        mejor_knn_param = n_neighbors\n",
    "\n",
    "knn_b = KNeighborsClassifier(n_neighbors=mejor_knn_param)\n",
    "knn_b.fit(X_train, y_train)\n",
    "man_pred_knn = knn_b.predict(X_test)\n",
    "man_prob_knn = knn_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "knn_precision = precision_score(y_test, man_pred_knn)\n",
    "knn_recall = recall_score(y_test, man_pred_knn)\n",
    "knn_f1 = f1_score(y_test, man_pred_knn)\n",
    "knn_auc = roc_auc_score(y_test, man_prob_knn)\n",
    "\n",
    "print(f\"Mejores parametros K-NN: {mejor_knn_param}\")\n",
    "print(f\"K-NN Precision: {knn_precision:.5f}, Recall: {knn_recall:.5f}, F1-Score: {knn_f1:.5f}, AUC: {knn_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez identificado el mejor valor para n_neighbors, se entrena un modelo KNN final utilizando este valor. Luego, se utiliza este modelo para hacer predicciones en el conjunto de prueba (X_test). \n",
    "\n",
    "Se calculan varias métricas para el modelo KNN: precisión 'precision_score', recall 'recall_score', f1-score 'f1_score' y AUC 'roc_auc_score'. Estas métricas proporcionan una visión detallada del rendimiento del modelo en datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regresion logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se prueba una serie de valores para el parámetro C, que controla la regularización del modelo. Los valores de C probados son 0.001, 0.01, 0.1, 1, 10 y 100. Para cada valor de C, se entrena un modelo de Regresión Logística y se evalúa utilizando validación cruzada con 5 particiones. \n",
    "\n",
    "Se selecciona el valor de C que proporciona el mejor promedio de f1-score en las particiones de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression parameters: C=10\n",
      "Logistic Regression Precision: 0.96629, Recall: 0.95556, F1-Score: 0.96089, AUC: 0.97799\n"
     ]
    }
   ],
   "source": [
    "mejor_logreg_score = 0\n",
    "mejor_logreg_params = None\n",
    "\n",
    "for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    logreg = LogisticRegression(C=C, max=10000)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(logreg, X_train, y_train, cv=5, scoring='f1')\n",
    "    avg = np.mean(scores)\n",
    "    \n",
    "    if avg > mejor_logreg_score:\n",
    "        mejor_logreg_score = avg\n",
    "        mejor_logreg_params = C\n",
    "\n",
    "logreg_b = LogisticRegression(C=mejor_logreg_params, max=10000)\n",
    "logreg_b.fit(X_train, y_train)\n",
    "man_pred_logreg = logreg_b.predict(X_test)\n",
    "man_prob_logreg = logreg_b.predict_proba(X_test)[:, 1]\n",
    "\n",
    "logreg_precision = precision_score(y_test, man_pred_logreg)\n",
    "logreg_recall = recall_score(y_test, man_pred_logreg)\n",
    "logreg_f1 = f1_score(y_test, man_pred_logreg)\n",
    "logreg_auc = roc_auc_score(y_test, man_prob_logreg)\n",
    "\n",
    "print(f\"mejores parametros de Regresion logistica: C={mejor_logreg_params}\")\n",
    "print(f\"Logistic Regression Precision: {logreg_precision:.5f}, Recall: {logreg_recall:.5f}, F1-Score: {logreg_f1:.5f}, AUC: {logreg_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el mejor valor para C identificado, se entrena un modelo de Regresión Logística final utilizando este valor. El modelo entrenado se usa para hacer predicciones en el conjunto de prueba (X_test). \n",
    "\n",
    "Se calculan las mismas métricas de evaluación que para KNN, esto permite comparar el rendimiento del modelo de Regresión Logística con el del modelo KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuadro de comparación manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Modelo  Precision    Recall  f1-score       AUC\n",
      "0                 K-NN   0.914894  0.955556  0.934783  0.961006\n",
      "1  Logistic Regression   0.966292  0.955556  0.960894  0.977987\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Modelo': ['K-NN', 'Logistic Regression'],\n",
    "    'Precision': [knn_precision, logreg_precision],\n",
    "    'Recall': [knn_recall, logreg_recall],\n",
    "    'f1-score': [knn_f1, logreg_f1],\n",
    "    'AUC': [knn_auc, logreg_auc]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(results)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del ajuste manual y automático de hiperparámetros para los modelos KNN y Regresión Logística son iguales, se puede concluir que el ajuste manual fue tan efectivo como el ajuste automático. Esto indica que el rango de hiperparámetros probado manualmente cubrió de manera adecuada las mejores opciones disponibles para ambos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}